---
title: 'Data 622 Homework 4: Mental Health Data Modeling'
author: 'Group 4: Dennis Pong, Katie Evers, Richard Zheng, Devin Teran'
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    code_folding: hide
  pdf_document:
    toc: yes
    toc_depth: '3'
    number_sections: yes
    df_print: kable
    highlight: tango
  html_document:
    df_print: paged
    highlight: pygments
    number_sections: yes
    theme: readable
    toc: yes
    toc_depth: 2
    toc_float: no
    fontsize: 12
editor_options:
  chunk_output_type: inline
fontsize: 11pt
urlcolor: blue
---

```{r setup, cache=FALSE}

library(knitr)
library(tidyverse)
library(caret) # For createDataPartition, featureplot, classification report
library(skimr)    # Used for EDA
#library(corrplot) # For correlation matrix
library(mice) # Multivariate Imputation By Chained Equations
library(micemd)
library(parallel)
library(doParallel)
#library(plyr)
library(VIM)
library(ggplot2)
library(kableExtra)
library(stats)
library(tidymodels)
library(e1071)
library(vcd)

library(ggplot2)
library(Hmisc)
library(Boruta)
## Global options
# ---------------------------------

options(max.print="108")
opts_knit$set(width=31)
```

# **Loading data**

```{r loading-data}
# getwd()
setwd("~/Data 622/repos/data622_fa2021/hw4")
adhd_data <- readxl::read_excel('ADHD_data.xlsx', sheet = "Data", .name_repair = "universal", na = "")

# dim(adhd_data)
str(adhd_data)

# loan_raw <- read.csv('https://raw.githubusercontent.com/metis-macys-66898/data622_fa2021/main/hw3/data/Loan_approval.csv', header = TRUE, na.strings = " ")
# loan_raw[loan_raw==""] <- NA
# loan_raw <- loan_raw %>% mutate_if(is.character, factor)
# loan <- loan_raw
```

## Data Processing Steps

I employed a couple strategies into transforming the data before we can apply models.

-   Imputing only when necessary. Imputing by applying the right method for the right variable type.

-   Make sure to make the fields into factors when they are categorical variables.

```{r}

aggr_plot <- aggr(adhd_data, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
# look for ways to rename the column count
```

Removing Initial as it provides no values to any models. Also, I removed Psych.meds. as it has 67% missing.

```{r}

adhd_data_pre_imp <- adhd_data %>% select(-c('Initial','Psych.meds.'))
skim(adhd_data_pre_imp) %>% dplyr::filter( n_missing > 0 ) 

```

```{r}
adhd_data_pre_imp <- adhd_data_pre_imp %>% mutate(NonSubstDx =  as.factor(Non.subst.Dx)  ,
                                                  SubstDx = as.factor(Subst.Dx) ,
                                                  Abuse = factor(Abuse, ordered = TRUE), 
                                                  Alcohol = as.factor(Alcohol)
)


adhd_data_pre_imp <- adhd_data_pre_imp %>%  mutate_if(is.numeric, factor)
skim(adhd_data_pre_imp)
adhd_data_pre_imp1 <- adhd_data_pre_imp %>% mutate(Education = as.numeric(Education)  )
skim(adhd_data_pre_imp1)
# skim(adhd_data_pre_imp)
```

### Imputation

More specifically, I separated the variables with missing values into the following categories:

-   **Categorical Variables with more than 2 levels:** Subst.Dx, NonSubstDx, Opioids, Sedative.hypnotics, Stimulants, Cocaine, THC, Alcohol - polyreg

-   **Categorical Variables with 2 levels:** Disorderly.Conduct, Hx.of.Violence, Court.order - logreg

-   **Discrete variable (ordered) with more than 2 levels:** Abuse - polr

-   **Continuous Variables:** Education **- ~~pmm~~ -\> norm**

```{r mice.par}

init <- mice(adhd_data_pre_imp1, maxit=0) 
meth <- init$method
predM <- init$predictorMatrix
meth[c('Education')] <- 'pmm'
meth[c('Disorderly.Conduct', 'Hx.of.Violence', 'Court.order')] <- 'logreg'
meth[c('Subst.Dx', 'NonSubstDx' , 'Opioids', 'Sedative.hypnotics', 'Stimulants', 'Cocaine', 'THC', 'Alcohol')] <- 'polyreg'
meth[c('Abuse')] = 'polr'
meth[c('Age','Sex','Race','ADHD.Q1','ADHD.Q2','ADHD.Q3','ADHD.Q4','ADHD.Q5','ADHD.Q6','ADHD.Q7','ADHD.Q8','ADHD.Q9','ADHD.Q10','ADHD.Q11','ADHD.Q12','ADHD.Q13','ADHD.Q14','ADHD.Q15','ADHD.Q16','ADHD.Q17','ADHD.Q18','ADHD.Total','MD.Q1a','MD.Q1b','MD.Q1c','MD.Q1d','MD.Q1e','MD.Q1f','MD.Q1g','MD.Q1h','MD.Q1i','MD.Q1j','MD.Q1k','MD.Q1L','MD.Q1m','MD.Q2','MD.Q3','MD.TOTAL','Suicide')] = ''

# adhd_data_imp1 <- mice(adhd_data_pre_imp1, method=meth, predictorMatrix=predM, seed=501)
# adhd_data_imp1 <- parlmice(adhd_data_pre_imp1, method=meth, predictorMatrix=predM, cluster.seed=501, m = 4, n.core = 4, n.imp.core = 100)

# no_cores <- detectCores() - 1
# 
# cl<-makePSOCKcluster(no_cores)
# 
# registerDoParallel(cl)
# 
# start.time<-proc.time()
# 
# adhd_data_imp1 <- mice.par(adhd_data_pre_imp1, method=meth, predictorMatrix=predM, seed=301, m = 5)
# 
# stop.time<-proc.time()
# 
# run.time<-stop.time -start.time
# 
# print(run.time)
# 
# stopCluster(cl)
# user  system elapsed 
#   1.826   4.303 264.775 
```

```{r parlmice}

# abandoned this method as it's not always consistent
# cl<-makePSOCKcluster(no_cores)
# registerDoParallel(cl)
#   
# start.time<-proc.time()
#   
# adhd_data_imp1 <- parlmice(adhd_data_pre_imp1, method=meth, predictorMatrix=predM, cluster.seed=501, m = 4, n.core = 4, n.imp.core = 1)
# 
# stop.time<-proc.time()
# 
# run.time<-stop.time -start.time
# 
# print(run.time)
# 
# stopCluster(cl)
```

#### Examining the imputations

Examining the imputations for Education. As the 50-th percentile before was 12, we picked an impute that is exactly that. Impute \#4 fits the bill.

```{r}
# str(adhd_data_imp1)
# skim(adhd_data_imp1) %>% dplyr::filter( n_missing > 0 )
# 
#Eduation
# adhd_data_imp1$imp$Education
# adhd_data_pre_imp1[140:142,]
# 
# 
# #Age
# adhd_data_imp1$imp$Alcohol

```

```{r decision}
# adhd_data_2 <- complete(adhd_data_imp1, 4) # 2nd argument if not provided is defaulted to 1
```

```{r adhd_data_2}

# skim(adhd_data_2) %>% dplyr::filter( n_missing > 0 )
# # # saving a R data frame

# saveRDS(adhd_data_2, "adhd_data_2.rds")


```

Ended up dropping 29 records as even there are other means of imputing the missing records manually. I just don't think it's trustworthy when advanced algorithms did not end up imputing them. The need to have complete cases, except for the suicide variable for section of clustering and PCA where suicide variable is not the response variable, or variable of interest, is the ultimate reason why I had to drop any records with even a missing field from the dataset.

```{r load.RData}
# loading rds object

# adhd_data_2 <- readRDS("adhd_data_2.rds")

# adhd_data_imp1$imp$Suicide
# 41	NA	NA	NA	NA	NA
# 49	NA	NA	NA	NA	NA
# 53	NA	NA	NA	NA	NA
# 67	NA	NA	NA	NA	NA
# 73	NA	NA	NA	NA	NA
# 106	NA	NA	NA	NA	NA
# 117	NA	NA	NA	NA	NA
# 122	NA	NA	NA	NA	NA
# 129	NA	NA	NA	NA	NA
# 131


# adhd_data_pre_imp1[complete.cases(adhd_data_pre_imp1[ , -49]),]

# saved 3 records
# adhd_data_3 <- adhd_data_2[complete.cases(adhd_data_2[ , -49]),]




```

```{r load.adhd_data_3}


# Saving the records 
# saveRDS(adhd_data_3, "adhd_data_3.rds")
#Loading the records
adhd_data_3 <- readRDS("adhd_data_3.rds")
```

#### Count for each Education / suicide attempt

```{r "Education~Suicide"}

ggplot(adhd_data_3, aes(x = Education, fill = Suicide)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange", "purple", "cyan4"),
                    guide = F) +
  theme_minimal() +
  facet_wrap(~Suicide, ncol = 1) +
  coord_flip()
mosaic(~ Education + Suicide, data = adhd_data_3)
```

#### Count for each Subst.Dx / suicide attempt

```{r "Subst.Dx~Suicide"}

ggplot(adhd_data_3, aes(x = Subst.Dx, fill = Suicide)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange", "purple", "cyan4"),
                    guide = F) +
  theme_minimal() +
  facet_wrap(~Suicide, ncol = 1) +
  coord_flip()
mosaic(~ Subst.Dx + Suicide, data = adhd_data_3)
```

#### Count for each Non.subst.Dx / suicide attempt

```{r "Non.subst.Dx~Suicide"}

ggplot(adhd_data_3, aes(x = Non.subst.Dx, fill = Suicide)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange", "purple", "cyan4"),
                    guide = F) +
  theme_minimal() +
  facet_wrap(~Suicide, ncol = 1) +
  coord_flip()
mosaic(~ Non.subst.Dx + Suicide, data = adhd_data_3)
```

#### Count for each Abuse / Suicide

```{r "Abuse~Suicide"}

ggplot(adhd_data_3, aes(x = Abuse, fill = Suicide)) +
  geom_bar(alpha = 0.8) +
  scale_fill_manual(values = c("darkorange", "purple", "cyan4", "black"),
                    guide = F) +
  theme_minimal() +
  facet_wrap(~Suicide, ncol = 1) +
  coord_flip()
mosaic(~ Abuse + Suicide, data = adhd_data_3)
```

## Clustering Method

```{r Clustering}




```

## Principal Component Analysis

```{r PCA}




```

## Xtreme Gradient Boosting (XGBoost)

```{r xgboost}
# need to remove Suicide null 



```

## Support Vector Machine (SVM)

SVM will help us decide on optimal decision boundary which can then help classify our labeled data. We're going to model for the response variable suicide attempts with the adhd\_data\_3 dataset with both a radial and a linear kernel to try to find the decision boundary as we don't know whether this is a non-linear problem or linear problem.

```{r svm}
dim(adhd_data_3)
# skim(adhd_data_3) 
adhd_data_4 <- adhd_data_3[complete.cases(adhd_data_3),]
dim(adhd_data_4)
```

```{r}

adhd_data_4_matx = as.matrix(adhd_data_4)

df.corr.p = as.data.frame(rcorr(adhd_data_4_matx)$P)

# removing Suicide, and repeated columns
correlation_table <- cbind(rownames(df.corr.p), df.corr.p[, 49])[-c(49,51,52) , ]
correlation_table %>%
  kbl(caption = "Correlation with Suicide") %>%
  kable_material_dark()
```

Here are the factors that has at least a 30% correlation with Suicide:

-   Age

-   ADHD.Q6

-   ADHD.Q9

-   ADHD.Q11

-   ADHD.Q12

-   ADHD.Q13

-   ADHD.Q17

-   ADHD.Q18

-   MD.Q1c

-   MD.Q1e

-   MD.Q1m

-   THC

-   Stimulants

-   Disorderly.Conduct

-   NonSubstDx

We further pear down the list of factors to that of correlation coefficient .500 or above.

```{r ge.5}
svm_selected <- as.data.frame(cbind(rownames(df.corr.p[df.corr.p[, 49] >= .5,]), df.corr.p[df.corr.p[, 49]>= .5, 49 ]))
svm_selected <-  svm_selected[complete.cases(svm_selected), ] 
rownames(svm_selected) <- seq(length=nrow(svm_selected))
svm_selected

adhd <- adhd_data_4 %>% select(c(svm_selected$V1, 'Suicide' )) %>% select(-c(Non.subst.Dx))
```

```{r radial }
set.seed(45)
indexes = createDataPartition(adhd$Suicide, p = .85, list = F) # results not in a List
train = adhd[indexes, ]
test = adhd[-indexes, ]
 
wts <- 100 / table(test$Suicide)
wts

radial_svm = svm(Suicide~., data=train, class.weights = wts, C = 13)
print(radial_svm)
 
test$pred = predict(radial_svm, test)
 
confusionMatrix(test$pred, test$Suicide)

```

```{r linear}
linear_svm = svm(factor(Suicide)~., data=train, kernel = "linear", type = 'C-classification', cost = 10, scale = F, class.weights = wts)
print(linear_svm)
 
test$pred = predict(linear_svm, test)
 
confusionMatrix(test$pred, test$Suicide)

```

Linear SVM performs better with a higher Balanced Accuracy.

------------------------------------------------------------------------

```{r}
# set.seed(688)
# # recoding Loan_Status back to categorical variable
# loan_knn2$Loan_Status <- as.factor(loan_knn2$Loan_Status)
# str(loan_knn2)
# 
# 
# # Data Partitioning
# trainIndex <- createDataPartition(loan_knn2$Loan_Status, p = .8, list = FALSE, times = 1)
# knn_train <- loan_knn2[trainIndex,]
# knn_test  <- loan_knn2[-trainIndex,]
# 
# 
# 
# str(knn_train)
```

```{r}
# trControl <- trainControl(method  = "repeatedcv",
#                           repeats  = 11)
# knn.fit <- train(Loan_Status ~ .,
#              method     = "knn",
#              tuneGrid   = expand.grid(k = 1:10),
#              trControl  = trControl,
#              preProcess = c("center","scale"),
#              data       = knn_train
#              )
```

```{r}

# knn_pred <- predict(knn.fit, newdata = knn_test)
# # options('max.print' = 100)  
# # getOption("max.print")
# confusionMatrix(knn_pred, knn_test$Loan_Status)


```
